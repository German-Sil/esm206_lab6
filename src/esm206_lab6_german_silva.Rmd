---
title: "Lab 6 Notes"
author: "German Silva"
date: "11/1/2021"
output: html_document
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Attach packages
library(tidyverse)
library(palmerpenguins)
library(broom)
library(equatiomatic)
```

## Example of rank-based test

Alternatives to parametric tests (t-tests and ANOVA)

we'll make our own samples, using a pseudorandom generator.

```{r}
set.seed(1414)

gp_1 <- sample.int(20, size = 15, replace = TRUE)

set.seed(1424)
gp_2 <- sample.int(30, size = 15, replace = TRUE)
```

```{r}
hist(gp_1)

hist(gp_2)

```

try a t-test:
```{r}
t.test(gp_1, gp_2)
```

What is the meaning of the p-value?

the p-value of 0.198 means that is the two groups had the same mean that there would be a 19.8% chance that we would get sample means *at least this different* from each other (this is with taking into account spread and n).

we retain (fail to reject) the null hypothesis. >> there is no significant difference between the means of group 1 and group 2.

Warning: People get weirdly upset if you say you "accept" the null hypothesis

Now let's compare this to a rank-based test.

## Mann-Whitney U unpaired rank-based test

```{r}
mwu <- wilcox.test(gp_1, gp_2)

mwu
```

the p-value of 0.28 means that if the two groups had the same ranks that there would be a 28% chance that we would get sample ranks *at least this different* from each other by random chance alone.

There is no significant difference in ranks (often you'll see medians) between group 1 and group 2 (statistical summary). 